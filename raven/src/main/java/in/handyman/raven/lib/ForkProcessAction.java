package in.handyman.raven.lib;

import com.fasterxml.jackson.databind.node.ObjectNode;
import com.zaxxer.hikari.HikariDataSource;
import in.handyman.raven.action.Action;
import in.handyman.raven.action.IActionExecution;
import in.handyman.raven.connection.ResourceAccess;
import in.handyman.raven.exception.HandymanException;
import in.handyman.raven.lib.model.ForkProcess;
import in.handyman.raven.process.Context;
import in.handyman.raven.process.Process;
import in.handyman.raven.process.ProcessEngine;
import in.handyman.raven.util.CommonQueryUtil;
import lombok.extern.log4j.Log4j2;
import org.apache.logging.log4j.MarkerManager;

import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.Executors;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;

/**
 * Auto Generated By Raven
 */
@Action(actionName = "ForkProcess")
@Log4j2
public class ForkProcessAction implements IActionExecution {

    private final ForkProcess forkProcess;
    private final Context context;
    private final MarkerManager.Log4jMarker aMarker;

    public ForkProcessAction(final Context context, final Object forkProcess) {
        this.forkProcess = (ForkProcess) forkProcess;
        this.context = context;
        this.aMarker = new MarkerManager.Log4jMarker("ForkProcess");
        this.context.getDetailMap().putPOJO("context", this.forkProcess);
    }

    @Override
    public void execute() throws Exception {
        var name = forkProcess.getName();
        var fileRelativePath = forkProcess.getSource();
        var processName = forkProcess.getTarget();
        var dbSrc = forkProcess.getDatasource();
        var forkBatchSize = forkProcess.getForkBatchSize();
        var forkBatchSizeInt = (forkBatchSize != null && !forkBatchSize.isEmpty()) ? Integer.parseInt(forkBatchSize) : 1;
        var sql = forkProcess.getValue();
        var processId = context.getProcessId();

        log.info(aMarker, " id#{}, name#{}, forked process#{}, calledFile#{}, db=#{}", processId, name, processName, fileRelativePath, dbSrc);
        final HikariDataSource source = ResourceAccess.rdbmsConn(dbSrc);
        final Set<Process> processes = new HashSet<>();
        try (var conn = source.getConnection()) {
            try (var stmt = conn.createStatement()) {
                final Map<String, String> configContext = context.getContext();
                final ObjectNode detailMap = context.getDetailMap();

                try (var rs = stmt.executeQuery(sql)) {
                    var columnCount = rs.getMetaData().getColumnCount();
                    while (rs.next()) {
                        CommonQueryUtil.addKeyConfig(configContext, detailMap,
                                rs, columnCount, "");
                        final Process process = ProcessEngine.newInstanceProcess(fileRelativePath, processName, context.getProcessId(), configContext);
                        processes.add(process);
                    }
                }
            }
        }
        var executor = Executors.newWorkStealingPool();
        final AtomicInteger counter = new AtomicInteger();
        final AtomicInteger batchNoAtomic = new AtomicInteger(1);
        processes.stream()
                .collect(Collectors.groupingBy(it -> counter.getAndIncrement() / forkBatchSizeInt))
                .values().forEach(processes1 -> {
                    final int batchNo = batchNoAtomic.getAndIncrement();
                    final int size = processes1.size();
                    log.info(aMarker, "Started Executing Fork-Process for batch-id#{} with batch-size#{}", batchNo, size);
                    var countDownLatch = new CountDownLatch(size);
                    processes1.forEach(process -> {
                        var processWorker = new LambdaCallable(process, countDownLatch);
                        executor.submit(processWorker);
                    });
                    try {
                        countDownLatch.await();
                    } catch (InterruptedException e) {
                        throw new HandymanException("ForkProcess failed for batch " + batchNo, e);
                    }
                });


    }

    @Override
    public boolean executeIf() throws Exception {
        return forkProcess.getCondition();
    }
}
