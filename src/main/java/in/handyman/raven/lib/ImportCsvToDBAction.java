package in.handyman.raven.lib;

import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.MappingIterator;
import com.fasterxml.jackson.dataformat.csv.CsvMapper;
import com.fasterxml.jackson.dataformat.csv.CsvSchema;
import in.handyman.raven.exception.HandymanException;
import in.handyman.raven.lambda.access.ResourceAccess;
import in.handyman.raven.lambda.action.ActionExecution;
import in.handyman.raven.lambda.action.IActionExecution;
import in.handyman.raven.lambda.doa.audit.ActionExecutionAudit;
import in.handyman.raven.lib.model.ImportCsvToDB;

import java.io.File;
import java.io.IOException;
import java.lang.Exception;
import java.lang.Object;
import java.lang.Override;
import java.util.*;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;

import in.handyman.raven.util.ExceptionUtil;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.jdbi.v3.core.Jdbi;
import org.jdbi.v3.core.statement.PreparedBatch;
import org.jdbi.v3.core.statement.Update;
import org.slf4j.Logger;
import org.slf4j.Marker;
import org.slf4j.MarkerFactory;

/**
 * Auto Generated By Raven
 */
@ActionExecution(
    actionName = "ImportCsvToDB"
)
public class ImportCsvToDBAction implements IActionExecution {
  private final ActionExecutionAudit action;

  private final Logger log;

  private final ImportCsvToDB importCsvToDB;

  private final Marker aMarker;

  public ImportCsvToDBAction(final ActionExecutionAudit action, final Logger log,
      final Object importCsvToDB) {
    this.importCsvToDB = (ImportCsvToDB) importCsvToDB;
    this.action = action;
    this.log = log;
    this.aMarker = MarkerFactory.getMarker(" ImportCsvToDB:"+this.importCsvToDB.getName());
  }

  @Override
  public void execute() throws Exception {

    try {
      ControlDataCsvImportDetails controlDataCsvImportDetails=new ControlDataCsvImportDetails();

      validateTarget();
      Jdbi jdbi = createJdbiConnection(importCsvToDB.getTarget());

      int size = importCsvToDB.getValue().size();

      if (shouldUseParallelProcessing(size)) {
        executeInParallel(jdbi, size);
      } else {
        executeSequentially(jdbi);
      }
    } catch (Exception e) {
      log.error("Error in import csvToDb action", e);
      throw new HandymanException("Error in import csvToDb action", e, action);
    }
  }


  private void validateTarget() {
    if (Objects.isNull(importCsvToDB.getTarget())) {
      throw new HandymanException("Target connection not provided");
    }
    log.info("Resource provided " + importCsvToDB.getTarget());
  }

  private Jdbi createJdbiConnection(String target) {
    return ResourceAccess.rdbmsJDBIConn(target);
  }

  private boolean shouldUseParallelProcessing(int size) {
    return Integer.valueOf(importCsvToDB.getWriteThreadCount()) > 1 && size > 1;
  }

  private void executeInParallel(Jdbi jdbi, int size) throws InterruptedException {
    Integer writeThreadCount = Integer.valueOf(importCsvToDB.getWriteThreadCount());
    ExecutorService executorService = Executors.newWorkStealingPool(writeThreadCount);
    CountDownLatch latch = new CountDownLatch(size);

    for (String path : importCsvToDB.getValue()) {
      executorService.execute(() -> {
        try {
          doImport(jdbi, path);
        } finally {
          latch.countDown();
        }
      });
    }
    latch.await();
    executorService.shutdown();
  }

  private void executeSequentially(Jdbi jdbi) {
    for (String path : importCsvToDB.getValue()) {
      doImport(jdbi, path);
    }
  }

  private void doImport(final Jdbi jdbi, final String path) {
    File file = new File(path);
    validateFile(file);
    Integer batchSize = Integer.valueOf(importCsvToDB.getBatchSize());

    log.info("Found file " + path);
    if (file.isFile()) {

      processFile(batchSize, jdbi, file);
    } else if (file.isDirectory()) {
      processDirectory(batchSize, jdbi, file);
    }
  }

  private void validateFile(File file) {
    if (!file.exists()) {
      throw new HandymanException("File does not exist: " + file.getPath());
    }
  }

  private void processDirectory(final Integer batchSize, final Jdbi jdbi, File directory) {
    Optional.ofNullable(directory.listFiles()).ifPresent(files -> {
      for (File childFile : files) {
        doImport(jdbi, childFile.getAbsolutePath());
      }
    });
  }

  private void processFile(final Integer batchSize, final Jdbi jdbi, final File file) {
    List<Map<String, Object>> data = readObjectsFromCsv(file);

    if (!data.isEmpty()) {
      createTableAndInsertData(batchSize, jdbi, data);
    }
  }

  private List<Map<String, Object>> readObjectsFromCsv(final File file) {
    try {
      CsvSchema schema = CsvSchema.emptySchema().withHeader();
      CsvMapper csvMapper = new CsvMapper();
      MappingIterator<Map<String, Object>> mappingIterator = csvMapper.readerFor(new TypeReference<Map<String, Object>>() {}).with(schema).readValues(file);
      return mappingIterator.readAll();
    } catch (IOException e) {
      log.error("Error reading objects from CSV: {}", ExceptionUtil.toString(e));
      throw new HandymanException("Error reading objects from CSV", e, action);
    }
  }

  private void createTableAndInsertData(final Integer batchSize, final Jdbi jdbi, List<Map<String, Object>> data) {
    Map<String, Object> firstRow = data.get(0);
    final String delimiter = ",";
    String columnNames = String.join(delimiter, firstRow.keySet());
    String columnCleanedNames = columnNames.substring(0,columnNames.length()-1);

    String namedParams = firstRow.keySet().stream()
            .map(s -> ":" + s)
            .collect(Collectors.joining(delimiter));
    String namedCleanedParams = namedParams.substring(0,namedParams.length()-1);

    String createTableDdl = generateCreateTableDDL(firstRow.keySet());

    jdbi.inTransaction(handle -> {
      handle.execute(createTableDdl);
      return null; // No result needed
    });

    insertDataInBatches(batchSize, jdbi, data, columnCleanedNames, namedCleanedParams);
  }

  private String generateCreateTableDDL(Set<String> columnNames) {
    String cleanedTableColumns = columnNames.stream()
            .map(String::valueOf)
            .filter(s -> !s.isEmpty())
            .collect(Collectors.joining(" VARCHAR,", "", " VARCHAR"));

    String createTableDdl = "CREATE TABLE " + importCsvToDB.getTableName() + "(" + cleanedTableColumns + ");";
    return createTableDdl;
  }


  void insertSummaryAudit(final Jdbi jdbi, int rowCount, int executeCount, int errorCount, String comments, Long tenantId) {
    try {
      ControlDataCsvImportDetails summary = new ControlDataCsvImportDetails().builder().build();
      jdbi.useTransaction(handle -> {
        Update update = handle.createUpdate("  INSERT INTO "+""+
                " (assetId,filePath,fileName,tableName,totalRows,totalColumns,columnsList,documentType) " +
                " VALUES(:assetId,:filePath,:fileName,:tableName,:totalRows,:totalColumns,:columnsList,:documentType);");
        Update bindBean = update.bindBean(summary);
        bindBean.execute();
      });
    } catch (Exception exception) {
      log.error(aMarker, "error inserting into batch insert audit  {}", ExceptionUtil.toString(exception));
      HandymanException handymanException = new HandymanException(exception);
      HandymanException.insertException("error inserting into batch insert audit", handymanException, action);

    }
  }

  private void insertDataInBatches(final Integer batchSize, final Jdbi jdbi,
                                   List<Map<String, Object>> data,
                                   String columnNames,
                                   String namedParams) {

    AtomicInteger counter = new AtomicInteger();

    String insertSqlFormat = String.format("INSERT INTO %s (%s) VALUES (%s);",
            importCsvToDB.getTableName(),
            columnNames,
            namedParams);

    jdbi.inTransaction(handle -> {
      try (PreparedBatch batch = handle.prepareBatch(insertSqlFormat)) {
        data.forEach(row -> {
          batch.bindMap(row).add();
          if (counter.incrementAndGet() % batchSize == 0) {
            log.info("Added batch size {}", batch.execute().length);
          }
        });
        log.info("Added batch size {}", batch.execute().length); // Execute remaining
      }
      return counter.get();
    });

    log.info("Completed inserting {} rows", counter.get());
  }

  @Data
  @AllArgsConstructor
  @NoArgsConstructor
  @Builder
  static class ControlDataCsvImportDetails{
    private Long assetId;
    private String filePath;
    private String fileName;
    private String tableName;
    private Long totalRows;
    private Long totalColumns;
    private String columnsList;
    private String documentType;

  }

  @Override
  public boolean executeIf() throws Exception {
    return importCsvToDB.getCondition();
  }
}
