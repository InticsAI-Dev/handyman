package in.handyman.raven.lib;

import com.fasterxml.jackson.databind.ObjectMapper;
import in.handyman.raven.exception.HandymanException;
import in.handyman.raven.lambda.access.ResourceAccess;
import in.handyman.raven.lambda.action.ActionExecution;
import in.handyman.raven.lambda.action.IActionExecution;
import in.handyman.raven.lambda.doa.audit.ActionExecutionAudit;
import in.handyman.raven.lib.model.KafkaProductionResponse;
import in.handyman.raven.util.CommonQueryUtil;
import in.handyman.raven.util.InstanceUtil;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import okhttp3.*;
import org.jdbi.v3.core.Jdbi;
import org.jdbi.v3.core.result.ResultIterable;
import org.jdbi.v3.core.statement.Query;
import org.slf4j.Logger;
import org.slf4j.Marker;
import org.slf4j.MarkerFactory;

import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;

/**
 * Auto Generated By Raven
 */
@ActionExecution(
        actionName = "KafkaProductionResponse"
)
public class KafkaProductionResponseAction implements IActionExecution {
  private final ActionExecutionAudit action;
  private final Logger log;
  private final KafkaProductionResponse kafkaProductionResponse;
  private final Marker aMarker;
  private final String URI;
  private static final String SIT_EP_URL = "kafka.production.response.url";
  private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
  private final List<KafkaProductionInput> kafkaProductionInputs = new ArrayList<>();
  private static final MediaType MEDIA_TYPE_JSON = MediaType.parse("application/json; charset=utf-8");

  public KafkaProductionResponseAction(final ActionExecutionAudit action, final Logger log,
                                       final Object kafkaProductionResponse) {
    this.kafkaProductionResponse = (KafkaProductionResponse) kafkaProductionResponse;
    this.action = action;
    this.log = log;
    this.aMarker = MarkerFactory.getMarker("KafkaProductionResponse:" + this.kafkaProductionResponse.getName());
    this.URI = action.getContext().get(SIT_EP_URL);
  }

  @Override
  public void execute() throws Exception {
    try {
      final OkHttpClient httpclient = InstanceUtil.createOkHttpClient();
      final Jdbi jdbi = ResourceAccess.rdbmsJDBIConn(kafkaProductionResponse.getResourceConn());

      jdbi.useTransaction(handle -> {
        final List<String> formattedQuery = CommonQueryUtil.getFormattedQuery(kafkaProductionResponse.getQuerySet());
        AtomicInteger i = new AtomicInteger(0);
        for (String sqlToExecute : formattedQuery) {
          log.info(aMarker, "Executing query {} from index {}", sqlToExecute, i.getAndIncrement());
          Query query = handle.createQuery(sqlToExecute);
          ResultIterable<KafkaProductionInput> resultIterable = query.mapToBean(KafkaProductionInput.class);
          List<KafkaProductionInput> processingExecutorInputs = resultIterable.stream().collect(Collectors.toList());
          kafkaProductionInputs.addAll(processingExecutorInputs);
          log.info(aMarker, "Executed query from index {}", i.get());
        }
      });

      log.info(aMarker, "KafkaProductionResponse action total rows returned from the query {}", kafkaProductionInputs.size());

      // Process each input
      for (KafkaProductionInput input : kafkaProductionInputs) {
        try {
          String requestTxnId = input.getRequestTxnId();
          log.info(aMarker, "Processing KafkaProductionResponse for requestTxnId: {}", requestTxnId);

          // Check if requestTxnId already exists in the output table
          String existingResponse = jdbi.withHandle(handle -> {
            return handle.createQuery(
                            "SELECT production_response FROM " + kafkaProductionResponse.getOutputTable() +
                                    " WHERE requestTxnId = :requestTxnId AND status = :status")
                    .bind("requestTxnId", requestTxnId)
                    .bind("status", "SUCCESS")
                    .mapTo(String.class)
                    .findFirst()
                    .orElse(null);
          });

          if (existingResponse != null && !existingResponse.isEmpty()) {
            log.info(aMarker, "requestTxnId {} already exists in output table, inserting new entry with existing response", requestTxnId);
            insertResponseDetails(jdbi, input, "SUCCESS", existingResponse, "Successfully reused existing response");
            continue;
          }

          Map<String, String> requestBody = new HashMap<>();
          requestBody.put("requestTxnId", requestTxnId);
          String requestJson = OBJECT_MAPPER.writeValueAsString(requestBody);

          Request request = new Request.Builder()
                  .url(URI)
                  .post(RequestBody.create(requestJson, MEDIA_TYPE_JSON))
                  .build();

          if (log.isInfoEnabled()) {
            log.info(aMarker, "The Request Details url: {}", URI);
          }

          try (Response response = httpclient.newCall(request).execute()) {
            if (response.body() == null) {
              log.error(aMarker, "Null response body for requestTxnId: {}", requestTxnId);
            }
            String responseBody = response.body().string();
            int statusCode = response.code();

            String status;
            String message;
            switch (statusCode) {
              case 200:
                Map<String, Object> responseMap = OBJECT_MAPPER.readValue(responseBody, Map.class);
                String detail = (String) responseMap.get("detail");

                switch (detail) {
                  case "SUCCESS":
                    log.info(aMarker, "Successfully retrieved payload for requestTxnId: {}", requestTxnId);
                    status = "SUCCESS";
                    message = "Successfully retrieved payload";
                    action.getContext().put(kafkaProductionResponse.getName() + ".isSuccessful", "true");
                    action.getContext().put(kafkaProductionResponse.getName() + ".response", responseBody);
                    break;
                  case "Error in Production Payload":
                    log.error(aMarker, "Production Payload error for requestTxnId: {}", requestTxnId);
                    message = "Production Payload error";
                    throw new HandymanException("Error in Production Payload for requestTxnId: " + requestTxnId);
                  case "No data found":
                    log.warn(aMarker, "No data found for requestTxnId: {}", requestTxnId);
                    message = "No data found";
                    throw new HandymanException("No data found for requestTxnId: " + requestTxnId);
                  default:
                    log.error(aMarker, "Unexpected detail value in response: {}", detail);
                    message = "Unexpected response detail: " + detail;
                    throw new HandymanException("Unexpected response detail: " + detail);
                }
                break;
              case 403:
                log.error(aMarker, "Invalid request for requestTxnId: {}", requestTxnId);
                message = "Invalid request";
                throw new HandymanException("Invalid request for requestTxnId: " + requestTxnId);
              case 500:
                log.error(aMarker, "Application error for requestTxnId: {}", requestTxnId);
                message = "Application error";
                throw new HandymanException("Application error for requestTxnId: " + requestTxnId);
              default:
                log.error(aMarker, "Unexpected status code {} for requestTxnId: {}", statusCode, requestTxnId);
                message = "Unexpected status code: " + statusCode;
                throw new HandymanException("Unexpected status code: " + statusCode);
            }

            insertResponseDetails(jdbi, input, status, responseBody, message);

          } catch (Exception e) {
            action.getContext().put(kafkaProductionResponse.getName() + ".isSuccessful", "false");
            log.error(aMarker, "Error processing requestTxnId: {}", input.getRequestTxnId(), e);
            HandymanException handymanException = new HandymanException(e);
            HandymanException.insertException("KafkaProductionResponse failed for requestTxnId: " + input.getRequestTxnId(), handymanException, action);
            insertResponseDetails(jdbi, input, "FAILED", null, e.getMessage() != null ? e.getMessage() : "Unknown error");
          }

        } catch (Exception e) {
          action.getContext().put(kafkaProductionResponse.getName() + ".isSuccessful", "false");
          log.error(aMarker, "Error processing requestTxnId: {}", input.getRequestTxnId(), e);
          HandymanException handymanException = new HandymanException(e);
          HandymanException.insertException("KafkaProductionResponse failed for requestTxnId: " + input.getRequestTxnId(), handymanException, action);
          insertResponseDetails(jdbi, input, "FAILED", null, e.getMessage() != null ? e.getMessage() : "Unknown error");
        }
      }

      log.info(aMarker, "KafkaProductionResponse action completed");

    } catch (Exception e) {
      action.getContext().put(kafkaProductionResponse.getName() + ".isSuccessful", "false");
      log.error(aMarker, "Error in KafkaProductionResponse action", e);
      HandymanException handymanException = new HandymanException(e);
      HandymanException.insertException("KafkaProductionResponse failed", handymanException, action);
      throw handymanException;
    }
  }
    private void insertResponseDetails(Jdbi jdbi, KafkaProductionInput input, String status, String responseBody, String message) {
        jdbi.useHandle(handle -> handle.createUpdate(
                        "INSERT INTO " + kafkaProductionResponse.getOutputTable() + " (" +
                                "created_on, created_user_id, last_updated_on, last_updated_user_id, status, version, " +
                                "production_response, document_id, extension, origin_id, tenant_id, transaction_id, " +
                                "requestTxnId, fileName, batch_id, message) VALUES (" +
                                ":createdOn, :createdUserId, :lastUpdatedOn, :lastUpdatedUserId, :status, :version, " +
                                ":productionResponse::jsonb, :documentId, :extension, :originId, :tenantId, :transactionId, " +
                                ":requestTxnId, :fileName, :batchId, :message)")
                .bind("createdOn", LocalDateTime.now())
                .bind("createdUserId", input != null ? input.getTenantId() : null)
                .bind("lastUpdatedOn", LocalDateTime.now())
                .bind("lastUpdatedUserId", input != null ? input.getTenantId() : null)
                .bind("status", status)
                .bind("version", 1)
                .bind("productionResponse", responseBody != null && !responseBody.isEmpty() ? responseBody : null)
                .bind("documentId", input != null ? input.getDocumentId() : null)
                .bind("extension", input != null ? input.getExtension() : null)
                .bind("originId", input != null ? input.getOriginId() : null)
                .bind("tenantId", input != null ? input.getTenantId() : null)
                .bind("transactionId", input != null ? input.getTransactionId() : null)
                .bind("requestTxnId", input != null ? input.getRequestTxnId() : null)
                .bind("fileName", input != null ? input.getFileName() : null)
                .bind("batchId", input != null ? input.getBatchId() : null)
                .bind("message", message != null ? message : "Unknown ERROR")
                .execute());
        log.info(aMarker, "Inserted audit details for requestTxnId: {} with status: {} and message: {}",
                input != null ? input.getRequestTxnId() : "N/A", status, message);
    }

  @Override
  public boolean executeIf() throws Exception {
    return kafkaProductionResponse.getCondition();
  }

  @AllArgsConstructor
  @NoArgsConstructor
  @Data
  @Builder
  public static class KafkaProductionInput {
    private String requestTxnId;
    private String documentId;
    private String extension;
    private String originId;
    private Long tenantId;
    private String transactionId;
    private String fileName;
    private String batchId;
    private Long rootPipelineId;
  }
}